# 2장 벡터가 어떻게 의미를 가지게 되는가
## 2.1. 자연어 계산과 이해
임베딩에 자연어 의미를 함축하는 방법은 자연어의 통계적 패턴 정보를 통째로 넣는 것이다.
> 1. 문장에 어떤 단어가 많이 쓰였는가 - Deep Averaging Network
> 2. 단어가 어떤 순서로 등장하는가 - ELMo, GPT
> 3. 문장에 어떤 단어가 같이 나타나는가 - Word2Vec

1번을 백오브워즈(bag of words) 가정이라고 부른다. 문장에서 단어 사용 여부나 빈도만 고려하다보니 순서 정보는 무시한다.
따라서 이에 대척점에 있는 것이 2번 언어 모델이다. 언어 모델은 단어의 등장 순서를 학습해 주어진 단어 시퀀스가 얼마나 자연스러운지 확률을 부여한다.
3번 분포 가정에서는 어떤 단어가 함께 쓰였는지를 통해 그 주변 문맥을 유추할 수 있다.

## 2.2. 어떤 단어가 많이 쓰였는가
### 2.2.1. 백오브워즈 가정
문장에서의 단어를 중복 제거한 형태로 나열하고 각 단어의 문장 속 빈도를 수치화한다. 저자가 생각한 주제가 문서에서의 단어 사용으로 나타날 것이라는 가정이 깔려있다.
간단한 아이디어이지만 정보 검색 분야에서 많이 쓰인다고 한다. 쿼리에 가장 적절한 문서를 반환할때 쿼리를 백오브워즈 임베딩으로 변환하고 검색 대상 문서 임베딩 간 코사인 유사도를 구해 유사도가 가장 높은 문서를 사용자에게 노출하는 방법이다. 

### 2.2.2. TF-IDF
단어 빈도를 임베딩에 그대로 사용하는 것은 위험하다. 한국어의 조사의 경우 주제와 상관없이 빈도가 높다. 이를 보완하기 위해 제안된 기법이 TF-IDF 이다.
쉽게 말해 특정 문서에 한하여 빈도수가 높은 단어에 가중치를 부여하는 기법이다. 
> TF = A라는 단어가 문서 1에서 10번 사용되었다면 해당 값은 10\n
> DF = 특정 단어가 나타난 문서의 수, A라는 단어 문서 1과 3에만 등장했다면 해당 값은 2\n
> IDF = 전체 문서 수(N)를 해당 단어의 DF로 나눈 뒤 로그를 취한 값

### 2.2.3. Deep Averaging Network
백오브워즈 가정의 뉴럴 네트워크 버전

## 2.3. 단어가 어떤 순서로 쓰였는가
### 2.3.1. 통계 기반 언어 모델
단어 시퀀스에 확률을 부여하는 모델이다. 단어가 n개라면 n개 단어가 동시에 나타날 확률을 반환하는 모델이다. 즉 주어진 단어 시퀀스 다음에 무엇이 오는 게 자연스러운지 알 수 있다. 
> n-gram : n개의 단어를 뜻하는 용어, ex) 난폭 운전 = 2-gram
> 단점 : 해당 모델을 학습하는 데이터 셋에 특정 문장이 존재하지 않는다면 문법적으로 문제가 없는 문장도 말이 되지 않는 문장으로 취급한다.
> 해결 : 최대우도추정법에 n-gram 모델을 활용하면 확률을 근사할 수 있다. 
> *하지만 n-gram 모델도 추정하고자하는 문장에서 특정 단어의 빈도가 0일 경우, 확률을 0으로 부여한다. 

### 2.3.2. 뉴럴 네트워크 기반 언어 모델
주어진 단어 시퀀스를 가지고 다음 단어를 맞추는 과정에서 학습된다. 학습이 완료되면 모델의 중간 혹은 말단 계산 결과물을 단어나 문장의 임베딩으로 활용한다. 
> 마스크 언어 모델이 통계 기반 언어 모델과 차이점
> 1. 문장의 중간에 마스크를 씌워 놓고 예측
> 2. 양방향 학습이 가능하다. 
> *따라서 기존 언어 모델 기법 대비 임베딩 품질이 좋다. ex) BERT

## 2.4. 어떤 단어가 같이 쓰였는가
### 2.4.1. 분포 가정
자연어 처리에서 분포는 특정 범위, 즉 윈도우 내에 동시에 등장하는 이웃 단어 또는 문맥의 집합을 가리킨다. 분포 가정은 "단어의 의미는 곧 그 언어에서의 활용이다" 라는 철학에 기반한다. `빨래`, `세탁` 의 뜻을 모르는데 해당 단어와 함께 쓰인 단어들이 비슷하다면 서로 비슷한 의미의 단어일 가능성이 높다.

### 2.4.2. 분포와 의미 : 형태소
형태소란 의미를 가지는 최소 단위를 말한다. 언어학자들이 형태소를 분석하는 대표적인 기준으로는 `계열관계`가 있다.
이는 해당 형태소 자리에 다른 형태소가 대치되어 쓰일 수 있는가를 따지는 것이다. 

### 2.4.3. 분포와 의미 : 품사
언어학자들이 제시하는 품사 분류 기준은 기능, 의미, 형태 세가지다. *언어학에서 기능은 분포에 따라 분류되기도 한다.

### 2.4.4. 점별 상호 정보량(PMI, Pointwise Mutual Information)
두 단어의 등장이 독립일 때 대비해 얼마나 자주 같이 등장하는지를 수치화한 것이다. 여기서 사용되는 것이 `윈도우` 개념이다.
> 윈도우가 2라면 타깃 단어 앞뒤로 2개를 단어 시퀀스로 한다.

### 2.4.5. Word2Vec
분포 가정의 대표적인 모델이 `Word2Vec`이다. 기본 구조는 `CBOW`와 `Skip-gram` 등이 있으며 둘 모두 특정 타깃 단어 주변의 문맥 즉 분포 정보를 임베딩에 함축한다.